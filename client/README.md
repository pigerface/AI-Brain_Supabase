# AI Brain Supabase - Python å®¢æˆ¶ç«¯åº«

AI Brain Supabase çš„ Python å®¢æˆ¶ç«¯åº«å¥—ä»¶ï¼Œæä¾›å®Œæ•´çš„ RAG ç³»çµ±æ“ä½œæ¥å£èˆ‡å·¥å…·ã€‚

![Python](https://img.shields.io/badge/Python-3.12+-yellow)
![Supabase](https://img.shields.io/badge/Supabase-Client-green)
![pgvector](https://img.shields.io/badge/pgvector-Support-purple)

---

## ğŸ“‹ å®¢æˆ¶ç«¯æ¨¡çµ„æ¦‚è¦½

### æ ¸å¿ƒæ¨¡çµ„çµæ§‹
```
client/
â”œâ”€â”€ __init__.py                # Python å¥—ä»¶åˆå§‹åŒ–èˆ‡å°å‡º
â”œâ”€â”€ client.py                  # ğŸ”Œ ä¸»è¦ Supabase å®¢æˆ¶ç«¯æ¥å£
â”œâ”€â”€ cli.py                     # ğŸ’» å‘½ä»¤è¡Œå·¥å…·èˆ‡ CLI ä»‹é¢
â”œâ”€â”€ config.py                  # âš™ï¸ é…ç½®ç®¡ç†èˆ‡ç’°å¢ƒè®€å–å·¥å…·
â””â”€â”€ database.py                # ğŸ—„ï¸ æ•¸æ“šåº« ORM èˆ‡æŸ¥è©¢å·¥å…·
```

---

## ğŸ”Œ client.py - ä¸»è¦å®¢æˆ¶ç«¯æ¥å£

**çµ±ä¸€çš„ Supabase æ“ä½œé«˜ç´š API**

### ä¸»è¦åŠŸèƒ½
- **ğŸ”— é€£æ¥ç®¡ç†**ï¼šè‡ªå‹•è™•ç†æ•¸æ“šåº«é€£æ¥ã€èªè­‰èˆ‡é‡é€£
- **ğŸ§  RAG æ”¯æŒ**ï¼šé‡å°å‘é‡æœç´¢èˆ‡æ–‡æª”ç®¡ç†çš„å°ˆç”¨æ–¹æ³•  
- **ğŸ“Š è³‡æºç®¡ç†**ï¼šå®Œæ•´çš„ resourcesã€chunksã€embeddings CRUD
- **ğŸ” æ™ºèƒ½æœç´¢**ï¼šæ”¯æ´å…¨æ–‡æœç´¢ã€å‘é‡æœç´¢ã€æ··åˆæœç´¢
- **âš¡ æ‰¹æ¬¡æ“ä½œ**ï¼šé«˜æ•ˆçš„æ‰¹é‡æ•¸æ“šè™•ç†èˆ‡æ›´æ–°
- **ğŸ›¡ï¸ éŒ¯èª¤è™•ç†**ï¼šå®Œå–„çš„ç•°å¸¸è™•ç†èˆ‡è‡ªå‹•é‡è©¦æ©Ÿåˆ¶

### æ ¸å¿ƒé¡åˆ¥èˆ‡æ–¹æ³•

#### **SupabaseClient é¡åˆ¥**
```python
class SupabaseClient:
    """
    AI Brain Supabase çµ±ä¸€å®¢æˆ¶ç«¯æ¥å£
    
    æä¾› RAG ç³»çµ±çš„æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½ï¼š
    - æ•¸æ“šåº«é€£æ¥ç®¡ç†
    - è³‡æºèˆ‡åˆ†å¡Šæ“ä½œ
    - å‘é‡æœç´¢èˆ‡å…¨æ–‡æœç´¢
    - æ‰¹é‡æ•¸æ“šè™•ç†
    """
    
    def __init__(self, config: Optional[Config] = None)
    def get_config_info(self) -> Dict[str, str]
    def health_check(self) -> Dict[str, Any]
    def get_database_statistics(self) -> Dict[str, int]
    def close(self) -> None
```

#### **è³‡æºç®¡ç†æ–¹æ³•**
```python
# åª’é«”ä¾†æºç®¡ç†
def create_media_source(self, id: str, name: str, description: str, **kwargs) -> MediaSource
def get_media_source(self, source_id: str) -> Optional[MediaSource]
def list_media_sources(self) -> List[MediaSource]

# è³‡æºæ–‡æª”ç®¡ç†
def create_resource(self, remote_src_url: str, content_header: str, source_id: str, **kwargs) -> Resource
def get_resource(self, resource_uuid: str) -> Optional[Resource]
def get_resources_by_url(self, remote_src_url: str) -> Optional[Resource]
def list_resources(self, source_id: Optional[str] = None, limit: int = 100) -> List[Resource]

# æ–‡å­—åˆ†å¡Šç®¡ç†
def create_chunk(self, resource_uuid: str, chunk_order: int, chunking_text: str, **kwargs) -> Chunk
def get_chunk(self, chunk_uuid: str) -> Optional[Chunk]
def get_chunks_by_resource(self, resource_uuid: str) -> List[Chunk]
def update_chunk_embedding(self, chunk_uuid: str, embedding: List[float]) -> bool
```

#### **æœç´¢èˆ‡æŸ¥è©¢æ–¹æ³•**
```python
# å…¨æ–‡æœç´¢
def search_chunks_by_text(self, query: str, source_id: Optional[str] = None, limit: int = 10) -> List[Chunk]

# å‘é‡æœç´¢ (å¦‚æœ pgvector å¯ç”¨)
def search_chunks_by_embedding(self, embedding: List[float], threshold: float = 0.8, limit: int = 10) -> List[Chunk]

# æ··åˆæœç´¢
def hybrid_search_chunks(self, text_query: str, embedding: List[float], text_weight: float = 0.5, vector_weight: float = 0.5, limit: int = 10) -> List[Chunk]

# çµ±è¨ˆèˆ‡åˆ†æ
def get_resource_statistics(self, source_id: Optional[str] = None) -> Dict[str, int]
def get_chunk_statistics(self, resource_uuid: Optional[str] = None) -> Dict[str, int]
```

### ä½¿ç”¨ç¯„ä¾‹
```python
from client.client import create_client

# å‰µå»ºå®¢æˆ¶ç«¯
client = create_client()

# å¥åº·æª¢æŸ¥
status = client.health_check()
print(f"æ•¸æ“šåº«ç‹€æ…‹: {status['status']}")

# å‰µå»ºåª’é«”ä¾†æº
source = client.create_media_source(
    id="example_news",
    name="Example News",
    description="ç¯„ä¾‹æ–°èä¾†æº",
    category="news",
    lang="zh-TW"
)

# å‰µå»ºè³‡æº
resource = client.create_resource(
    remote_src_url="https://example.com/article-1",
    content_header="AI æŠ€è¡“ç™¼å±•è¶¨å‹¢",
    source_id="example_news",
    file_type="html",
    need_parsed=True
)

# å‰µå»ºæ–‡å­—åˆ†å¡Š
chunk = client.create_chunk(
    resource_uuid=resource.uuid,
    chunk_order=1,
    chunking_text="äººå·¥æ™ºæ…§æŠ€è¡“æ­£åœ¨å¿«é€Ÿç™¼å±•ï¼Œå½±éŸ¿å„å€‹ç”¢æ¥­...",
    description="AI ç™¼å±•æ¦‚è¿°"
)

# å…¨æ–‡æœç´¢
results = client.search_chunks_by_text("äººå·¥æ™ºæ…§", limit=5)
for chunk in results:
    print(f"æ‰¾åˆ°: {chunk.description}")

# é—œé–‰é€£æ¥
client.close()
```

---

## ğŸ’» cli.py - å‘½ä»¤è¡Œå·¥å…·

**å¼·å¤§çš„ CLI æ“ä½œä»‹é¢**

### ä¸»è¦åŠŸèƒ½
- **ğŸ’» å‘½ä»¤è¡Œé›†æˆ**ï¼šæä¾›å®Œæ•´çš„ CLI å‘½ä»¤æ”¯æŒ
- **ğŸ“Š æ•¸æ“šå°å…¥å°å‡º**ï¼šæ‰¹é‡è™•ç†æ–‡æª”èˆ‡å‘é‡æ•¸æ“š  
- **ğŸ”§ ç®¡ç†å·¥å…·**ï¼šæ•¸æ“šåº«ç¶­è­·ã€çµ±è¨ˆæŸ¥è©¢ã€å¥åº·æª¢æŸ¥
- **ğŸš€ è…³æœ¬å‹å¥½**ï¼šå¯èˆ‡ Shell è…³æœ¬ç„¡ç¸«é›†æˆè‡ªå‹•åŒ–
- **ğŸ“ è©³ç´°æ—¥èªŒ**ï¼šå®Œæ•´çš„æ“ä½œæ—¥èªŒèˆ‡é€²åº¦é¡¯ç¤º

### æ ¸å¿ƒ CLI å‘½ä»¤

#### **ç³»çµ±ç®¡ç†å‘½ä»¤**
```python
class SystemCommands:
    """ç³»çµ±ç®¡ç†ç›¸é—œå‘½ä»¤"""
    
    def health_check(self) -> None
        """åŸ·è¡Œç³»çµ±å¥åº·æª¢æŸ¥"""
        
    def show_status(self) -> None
        """é¡¯ç¤ºè©³ç´°ç³»çµ±ç‹€æ…‹"""
        
    def database_stats(self) -> None
        """é¡¯ç¤ºæ•¸æ“šåº«çµ±è¨ˆä¿¡æ¯"""
        
    def cleanup_database(self) -> None
        """æ¸…ç†æ•¸æ“šåº«ç„¡ç”¨æ•¸æ“š"""
```

#### **è³‡æºç®¡ç†å‘½ä»¤**
```python
class ResourceCommands:
    """è³‡æºç®¡ç†ç›¸é—œå‘½ä»¤"""
    
    def list_sources(self) -> None
        """åˆ—å‡ºæ‰€æœ‰åª’é«”ä¾†æº"""
        
    def create_source(self, id: str, name: str, description: str) -> None
        """å‰µå»ºæ–°çš„åª’é«”ä¾†æº"""
        
    def list_resources(self, source_id: Optional[str] = None) -> None
        """åˆ—å‡ºè³‡æºæ–‡æª”"""
        
    def import_resources(self, file_path: str, source_id: str) -> None
        """æ‰¹é‡å°å…¥è³‡æºæ–‡æª”"""
        
    def export_resources(self, output_path: str, source_id: Optional[str] = None) -> None
        """å°å‡ºè³‡æºæ–‡æª”"""
```

#### **æœç´¢èˆ‡åˆ†æå‘½ä»¤**
```python
class SearchCommands:
    """æœç´¢èˆ‡åˆ†æç›¸é—œå‘½ä»¤"""
    
    def search_text(self, query: str, limit: int = 10) -> None
        """åŸ·è¡Œå…¨æ–‡æœç´¢"""
        
    def search_similar(self, text: str, limit: int = 10) -> None
        """åŸ·è¡Œèªæ„ç›¸ä¼¼æœç´¢"""
        
    def analyze_chunks(self, resource_uuid: Optional[str] = None) -> None
        """åˆ†ææ–‡å­—åˆ†å¡Šçµ±è¨ˆ"""
        
    def benchmark_search(self, queries_file: str) -> None
        """åŸ·è¡Œæœç´¢æ€§èƒ½åŸºæº–æ¸¬è©¦"""
```

### CLI ä½¿ç”¨ç¯„ä¾‹
```bash
# ä½¿ç”¨ Python æ¨¡çµ„æ–¹å¼
python -m client.cli health-check
python -m client.cli list-sources
python -m client.cli search-text "AI ç™¼å±•"
python -m client.cli import-resources articles.json example_news

# ä½¿ç”¨ uv é‹è¡Œ
uv run python -m client.cli --help
uv run python -m client.cli database-stats
uv run python -m client.cli export-resources output.json --source example_news
```

---

## âš™ï¸ config.py - é…ç½®ç®¡ç†

**æ™ºèƒ½çš„ç’°å¢ƒé…ç½®ç®¡ç†**

### ä¸»è¦åŠŸèƒ½
- **ğŸ”§ ç’°å¢ƒè®€å–**ï¼šè‡ªå‹•è®€å– .envã€ç’°å¢ƒè®Šæ•¸ã€Supabase ç‹€æ…‹
- **âœ… é…ç½®é©—è­‰**ï¼šæª¢æŸ¥å¿…è¦é…ç½®é …å®Œæ•´æ€§èˆ‡æœ‰æ•ˆæ€§
- **ğŸ”„ å‹•æ…‹æ›´æ–°**ï¼šæ”¯æŒé‹è¡Œæ™‚é…ç½®æ›´æ–°èˆ‡é‡è¼‰
- **ğŸ›¡ï¸ å®‰å…¨è™•ç†**ï¼šæ•æ„Ÿä¿¡æ¯å®‰å…¨å­˜å„²èˆ‡è¨ªå•æ§åˆ¶
- **ğŸ“‹ é è¨­ç®¡ç†**ï¼šæ™ºèƒ½é è¨­å€¼èˆ‡é…ç½®ç¹¼æ‰¿

### æ ¸å¿ƒé…ç½®é¡åˆ¥

#### **Config é¡åˆ¥**
```python
class Config:
    """
    çµ±ä¸€é…ç½®ç®¡ç†é¡åˆ¥
    
    è‡ªå‹•è®€å–ä¸¦é©—è­‰æ‰€æœ‰å¿…è¦çš„é…ç½®é …ï¼š
    - Supabase é€£æ¥ä¿¡æ¯
    - æ•¸æ“šåº«é€£æ¥åƒæ•¸
    - API å¯†é‘°èˆ‡èªè­‰
    - æ‡‰ç”¨ç¨‹å¼è¨­å®š
    """
    
    # Supabase é…ç½®
    supabase_url: str
    supabase_anon_key: str
    supabase_service_role_key: str
    
    # æ•¸æ“šåº«é…ç½®
    database_url: str
    database_host: str
    database_port: int
    database_name: str
    database_user: str
    database_password: str
    
    # æ‡‰ç”¨é…ç½®
    log_level: str = "INFO"
    max_retries: int = 3
    timeout: int = 30
    
    @classmethod
    def from_env(cls) -> 'Config'
    @classmethod
    def from_file(cls, file_path: str) -> 'Config'
    def validate(self) -> bool
    def to_dict(self) -> Dict[str, Any]
```

#### **é…ç½®è®€å–æ–¹æ³•**
```python
# ç’°å¢ƒè®Šæ•¸è®€å–
def get_supabase_config() -> Dict[str, str]
    """å¾ Supabase CLI ç‹€æ…‹è®€å–é…ç½®"""

def get_database_config() -> Dict[str, str]
    """è§£ææ•¸æ“šåº«é€£æ¥é…ç½®"""

def get_env_config(prefix: str = "SUPABASE_") -> Dict[str, str]
    """è®€å–æŒ‡å®šå‰ç¶´çš„ç’°å¢ƒè®Šæ•¸"""

# é…ç½®é©—è­‰
def validate_connection(config: Config) -> Tuple[bool, str]
    """é©—è­‰é…ç½®æ˜¯å¦å¯ç”¨æ–¼é€£æ¥"""

def check_required_config(config: Config) -> List[str]
    """æª¢æŸ¥ç¼ºå¤±çš„å¿…è¦é…ç½®é …"""
```

### é…ç½®ä½¿ç”¨ç¯„ä¾‹
```python
from client.config import Config, get_supabase_config

# è‡ªå‹•è®€å–é…ç½®
config = Config.from_env()

# é©—è­‰é…ç½®
if config.validate():
    print("âœ… é…ç½®é©—è­‰æˆåŠŸ")
else:
    print("âŒ é…ç½®é©—è­‰å¤±æ•—")

# æ‰‹å‹•é…ç½®
config = Config(
    supabase_url="http://localhost:54331",
    database_url="postgresql://postgres:postgres@localhost:54332/postgres",
    log_level="DEBUG"
)

# å¾æ–‡ä»¶è®€å–
config = Config.from_file(".env.local")
```

---

## ğŸ—„ï¸ database.py - æ•¸æ“šåº« ORM

**RAG ç³»çµ±å°ˆç”¨æ•¸æ“šåº«æŠ½è±¡å±¤**

### ä¸»è¦åŠŸèƒ½
- **ğŸ—„ï¸ æ¨¡å‹å®šç¾©**ï¼šå®Œæ•´çš„ RAG ç³»çµ±æ•¸æ“šæ¨¡å‹ (Resources, Chunks, etc.)
- **ğŸ” é«˜ç´šæŸ¥è©¢**ï¼šè¤‡é›œæŸ¥è©¢ã€èšåˆã€çµ±è¨ˆåˆ†æå·¥å…·  
- **ğŸ§  å‘é‡æ“ä½œ**ï¼špgvector å‘é‡æœç´¢èˆ‡ç›¸ä¼¼åº¦è¨ˆç®—åŒ…è£å™¨
- **âš¡ æ€§èƒ½å„ªåŒ–**ï¼šæŸ¥è©¢å„ªåŒ–ã€ç´¢å¼•ç®¡ç†ã€é€£æ¥æ± 
- **ğŸ”„ é·ç§»æ”¯æŒ**ï¼šæ•¸æ“šåº« schema è®Šæ›´èˆ‡ç‰ˆæœ¬ç®¡ç†

### æ•¸æ“šæ¨¡å‹å®šç¾©

#### **åŸºç¤æ¨¡å‹é¡åˆ¥**
```python
from dataclasses import dataclass
from datetime import datetime
from typing import Optional, List, Dict, Any
from uuid import UUID

@dataclass
class MediaSource:
    """åª’é«”ä¾†æºæ¨¡å‹"""
    id: str
    name: str
    description: str
    category: Optional[str] = None
    lang: Optional[str] = None
    config: Dict[str, Any] = None
    created_at: datetime = None

@dataclass  
class Resource:
    """è³‡æºæ–‡æª”æ¨¡å‹"""
    uuid: UUID
    local_src_url: Optional[str]
    remote_src_url: Optional[str]
    content_time: datetime
    content_header: str
    content_authors: Optional[List[str]]
    source_id: str
    file_type: Optional[str]
    need_parsed: bool = False
    crawl_completed: bool = False
    created_at: datetime = None
    updated_at: datetime = None
    content_sha256: Optional[bytes] = None

@dataclass
class Chunk:
    """æ–‡å­—åˆ†å¡Šæ¨¡å‹"""  
    uuid: UUID
    resource_uuid: UUID
    parsed_uuid: Optional[UUID]
    image_uuid: Optional[UUID]
    source_id: str
    page: Optional[int]
    chunk_order: int
    chunk_setting_id: Optional[int]
    token_size: Optional[int]
    chunking_text: str
    description: Optional[str]
    chunk_embedding: Optional[List[float]]
    description_embedding: Optional[List[float]]
    created_at: datetime = None
    updated_at: datetime = None
```

#### **æŸ¥è©¢å·¥å…·é¡åˆ¥**
```python
class DatabaseQuery:
    """æ•¸æ“šåº«æŸ¥è©¢å·¥å…·é›†"""
    
    def __init__(self, connection_string: str)
    
    # åŸºç¤ CRUD æ“ä½œ
    def create(self, model: Any) -> Any
    def read(self, model_class: type, uuid: UUID) -> Optional[Any]
    def update(self, model: Any) -> bool
    def delete(self, model_class: type, uuid: UUID) -> bool
    
    # æ‰¹é‡æ“ä½œ
    def bulk_create(self, models: List[Any]) -> List[Any]
    def bulk_update(self, models: List[Any]) -> bool
    def bulk_delete(self, model_class: type, uuids: List[UUID]) -> int
    
    # è¤‡é›œæŸ¥è©¢
    def query(self, sql: str, params: Dict[str, Any] = None) -> List[Dict[str, Any]]
    def aggregate(self, model_class: type, aggregations: Dict[str, str]) -> Dict[str, Any]
    def join_query(self, models: List[type], conditions: str) -> List[Dict[str, Any]]
```

#### **å‘é‡æœç´¢å·¥å…·**
```python
class VectorSearch:
    """pgvector å‘é‡æœç´¢åŒ…è£å™¨"""
    
    def __init__(self, database_query: DatabaseQuery)
    
    # å‘é‡æ“ä½œ
    def add_embedding(self, chunk_uuid: UUID, embedding: List[float], kind: str = "chunk") -> bool
    def update_embedding(self, chunk_uuid: UUID, embedding: List[float], kind: str = "chunk") -> bool
    def get_embedding(self, chunk_uuid: UUID, kind: str = "chunk") -> Optional[List[float]]
    
    # ç›¸ä¼¼åº¦æœç´¢
    def similarity_search(self, query_embedding: List[float], threshold: float = 0.8, limit: int = 10) -> List[Chunk]
    def cosine_similarity(self, embedding1: List[float], embedding2: List[float]) -> float
    def euclidean_distance(self, embedding1: List[float], embedding2: List[float]) -> float
    
    # æ‰¹é‡å‘é‡æ“ä½œ
    def batch_add_embeddings(self, embeddings: Dict[UUID, List[float]]) -> int
    def reindex_vectors(self, force: bool = False) -> bool
```

### æ•¸æ“šåº«ä½¿ç”¨ç¯„ä¾‹
```python
from client.database import DatabaseQuery, VectorSearch, Resource, Chunk
from client.config import Config

# åˆå§‹åŒ–æ•¸æ“šåº«é€£æ¥
config = Config.from_env()
db = DatabaseQuery(config.database_url)

# å‰µå»ºè³‡æº
resource = Resource(
    uuid=UUID("12345678-1234-5678-9012-123456789012"),
    remote_src_url="https://example.com/article",
    content_header="AI ç™¼å±•è¶¨å‹¢",
    source_id="example_news",
    content_time=datetime.now()
)
created_resource = db.create(resource)

# æŸ¥è©¢è³‡æº
found_resource = db.read(Resource, resource.uuid)

# è¤‡é›œæŸ¥è©¢
results = db.query(
    "SELECT * FROM resources WHERE source_id = %(source_id)s AND created_at > %(date)s",
    {"source_id": "example_news", "date": "2025-01-01"}
)

# å‘é‡æœç´¢
vector_search = VectorSearch(db)
embedding = [0.1, 0.2, 0.3, ...]  # 1536 ç¶­å‘é‡
similar_chunks = vector_search.similarity_search(embedding, threshold=0.85, limit=5)

# çµ±è¨ˆæŸ¥è©¢
stats = db.aggregate(Resource, {
    "total_count": "COUNT(*)",
    "avg_chunks": "AVG(chunk_count)",
    "latest_date": "MAX(created_at)"
})
```

---

## ğŸš€ å¿«é€Ÿé–‹å§‹

### å®‰è£èˆ‡è¨­å®š
```bash
# ç¢ºä¿ Supabase æœå‹™é‹è¡Œ
./scripts/start.sh

# å®‰è£ Python ä¾è³´
uv sync

# æ¸¬è©¦é€£æ¥
python -c "from client.client import create_client; print('âœ… å®¢æˆ¶ç«¯å°±ç·’')"
```

### åŸºæœ¬ä½¿ç”¨æµç¨‹
```python
from client.client import create_client

# 1. å‰µå»ºå®¢æˆ¶ç«¯
client = create_client()

# 2. æª¢æŸ¥ç³»çµ±ç‹€æ…‹
health = client.health_check()
print(f"ç³»çµ±ç‹€æ…‹: {health['status']}")

# 3. å‰µå»ºåª’é«”ä¾†æº
source = client.create_media_source(
    id="my_source",
    name="My Source",
    description="æˆ‘çš„æ–‡æª”ä¾†æº"
)

# 4. æ·»åŠ è³‡æº
resource = client.create_resource(
    remote_src_url="https://example.com/doc",
    content_header="é‡è¦æ–‡æª”",
    source_id="my_source"
)

# 5. å‰µå»ºæ–‡å­—åˆ†å¡Š
chunk = client.create_chunk(
    resource_uuid=resource.uuid,
    chunk_order=1,
    chunking_text="é€™æ˜¯æ–‡æª”çš„é‡è¦å…§å®¹..."
)

# 6. æœç´¢å…§å®¹
results = client.search_chunks_by_text("é‡è¦")
for result in results:
    print(f"æ‰¾åˆ°: {result.chunking_text[:50]}...")

# 7. é—œé–‰é€£æ¥
client.close()
```

---

## ğŸ”§ é–‹ç™¼èˆ‡é™¤éŒ¯

### æ—¥èªŒé…ç½®
```python
import logging
from client.config import Config

# è¨­ç½®æ—¥èªŒç´šåˆ¥
config = Config.from_env()
config.log_level = "DEBUG"

logging.basicConfig(level=getattr(logging, config.log_level))
```

### éŒ¯èª¤è™•ç†
```python
from client.client import create_client, SupabaseClientError

try:
    client = create_client()
    result = client.search_chunks_by_text("query")
except SupabaseClientError as e:
    print(f"å®¢æˆ¶ç«¯éŒ¯èª¤: {e}")
except Exception as e:
    print(f"æœªé æœŸéŒ¯èª¤: {e}")
```

### æ€§èƒ½å„ªåŒ–
```python
# ä½¿ç”¨æ‰¹é‡æ“ä½œ
chunks_data = [...]  # å¤§é‡åˆ†å¡Šæ•¸æ“š
client.bulk_create_chunks(chunks_data)

# é€£æ¥æ± ç®¡ç†
client.configure_pool(min_connections=5, max_connections=20)

# æŸ¥è©¢å„ªåŒ–
client.enable_query_cache(ttl=300)  # 5 åˆ†é˜ç·©å­˜
```

---

## ğŸ“š åƒè€ƒè³‡æº

- [Supabase Python å®¢æˆ¶ç«¯](https://supabase.com/docs/reference/python/introduction)
- [pgvector æ–‡æª”](https://github.com/pgvector/pgvector)
- [PostgreSQL Python é©…å‹•](https://www.psycopg.org/psycopg3/)

---

**ğŸ’¡ æç¤º**: æ›´å¤šè©³ç´°ç¯„ä¾‹å’Œ API åƒè€ƒï¼Œè«‹åƒé–±ä¸»é …ç›® [README.md](../README.md)